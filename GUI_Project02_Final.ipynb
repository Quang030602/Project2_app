{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5738,
     "status": "ok",
     "timestamp": 1751111610417,
     "user": {
      "displayName": "Thao Nguyen",
      "userId": "13621871980693989521"
     },
     "user_tz": -420
    },
    "id": "5C9wWm8WTmsn",
    "outputId": "ff9197ba-fc94-4cee-94a8-907183c3db50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install underthesea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1751120144693,
     "user": {
      "displayName": "Thao Nguyen",
      "userId": "13621871980693989521"
     },
     "user_tz": -420
    },
    "id": "n_2OkWnvLdG0",
    "outputId": "cc4ddbbb-7125-4efb-996e-9ee3682d1fb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 00:51:40.049 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.051 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.051 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:40.063 No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-29 00:51:41.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:41.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.424 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:51:42.426 No runtime found, using MemoryCacheStorageManager\n",
      "C:\\Users\\quang\\AppData\\Local\\Temp\\ipykernel_13912\\655975243.py:355: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "2025-06-29 00:52:52.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "                 Model       AUC  Accuracy  Precision    Recall  F1-Score\n",
      "1                  SVM  0.939762  0.840261   0.987118  0.828938  0.901139\n",
      "2              XGBoost  0.937751  0.928741   0.946746  0.973631  0.960000\n",
      "0  Logistic Regression  0.937047  0.868171   0.976497  0.870859  0.920658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 00:52:52.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.733 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-29 00:52:52.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Write the Streamlit app to a Python file\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Project 02 - Company Recommendation & Candidate Classification\")\n",
    "st.caption(\"Team: Nguyen Quynh Oanh Thao - Nguyen Le Minh Quang\")\n",
    "\n",
    "menu = [\"Home\", \"About\"]\n",
    "choice = st.sidebar.selectbox('Menu', menu)\n",
    "\n",
    "\n",
    "if choice == 'Home':\n",
    "   st.subheader(\"Streamlit From Colab\")\n",
    "elif choice == 'About':\n",
    "   st.subheader(\"Requirements info\")\n",
    "\n",
    "st.set_page_config(page_title=\"Project 02\", layout=\"wide\")\n",
    "\n",
    "# Tabs for Topic 1 and Topic 2\n",
    "tab1, tab2 = st.tabs([\"üîç Topic 1: Company Recommendation\", \"üß† Topic 2: Candidate Classification\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"Topic 1: Content-Based Company Recommendation System\")\n",
    "\n",
    "\n",
    "with tab1:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import streamlit as st\n",
    "    import re\n",
    "    import gensim\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from gensim import models as gensim_models, corpora, similarities\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy.sparse import hstack\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # --- Text Preprocessing ---\n",
    "    def clean_tokens(tokens):\n",
    "        cleaned = [re.sub(r'\\d+', '', word) for word in tokens]\n",
    "        return [word.lower() for word in cleaned if word not in ['', ' ', ',', '.', '-', ':', '?', '%', '(', ')', '+', '/', 'g', 'ml']]\n",
    "\n",
    "    stop_words = set([\n",
    "        \"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"to\", \"from\", \"by\", \"of\", \"with\", \"and\", \"but\", \"or\", \"for\", \"nor\", \"so\", \"yet\",\n",
    "        \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\", \"be\", \"have\", \"do\", \"does\", \"did\",\n",
    "        \"was\", \"were\", \"will\", \"would\", \"shall\", \"should\", \"may\", \"might\", \"can\", \"could\", \"must\",\n",
    "        \"that\", \"this\", \"which\", \"what\", \"their\", \"these\", \"those\", \"https\", \"www\"\n",
    "    ])\n",
    "\n",
    "    def remove_stopwords(tokens):\n",
    "        return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # --- Load and Prepare Data ---\n",
    "    @st.cache_data\n",
    "    def load_and_process_data():\n",
    "        df = pd.read_excel(\"Overview_Companies.xlsx\")\n",
    "        df = df[['Company Name', 'Company overview']].dropna().copy()\n",
    "        df['tokens'] = df['Company overview'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "        df['tokens_cleaned'] = df['tokens'].apply(clean_tokens)\n",
    "        df['tokens_final'] = df['tokens_cleaned'].apply(remove_stopwords)\n",
    "        df = df[df['tokens_final'].str.len() > 0].copy()\n",
    "        df['joined_tokens'] = df['tokens_final'].apply(lambda tokens: ' '.join(tokens))\n",
    "        return df\n",
    "\n",
    "    df = load_and_process_data()\n",
    "\n",
    "    # --- ML Classification ---\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3), sublinear_tf=True, stop_words='english', min_df=2, max_df=0.8, norm='l2')\n",
    "    X = vectorizer.fit_transform(df['joined_tokens'])\n",
    "\n",
    "    # Dummy label for now: use KMeans or known labels\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    df['label'] = kmeans.fit_predict(X)\n",
    "    label_map = {0: 'Low', 1: 'Medium', 2: 'High'}\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "\n",
    "    # Encode & split\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df['label'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # --- Gensim Similarity Setup ---\n",
    "    dictionary = corpora.Dictionary(df['tokens_final'])\n",
    "    corpus = [dictionary.doc2bow(text) for text in df['tokens_final']]\n",
    "    tfidf_model = gensim_models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf_model[corpus]\n",
    "    index = similarities.SparseMatrixSimilarity(corpus_tfidf, num_features=len(dictionary))\n",
    "\n",
    "    # --- Charts -----\n",
    "    # ---- Define models BEFORE using them ----\n",
    "    models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, class_weight='balanced'),\n",
    "    \"Support Vector Machine\": SVC(probability=True, class_weight='balanced')}\n",
    "    # ---- Recalculate cosine feature and split ----\n",
    "    cosine_sim = cosine_similarity(X, X)\n",
    "    ref_sim = cosine_sim[0].reshape(-1, 1)\n",
    "    X_with_sim = hstack([X, ref_sim])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_with_sim, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "    # ---- Evaluate All Models ----\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "      model.fit(X_train, y_train)\n",
    "      y_pred = model.predict(X_test)\n",
    "      precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "      recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "      f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "      accuracy = accuracy_score(y_test, y_pred)\n",
    "      results[name] = {\n",
    "          \"Accuracy\": accuracy,\n",
    "          \"Precision\": precision,\n",
    "          \"Recall\": recall,\n",
    "          \"F1-score\": f1\n",
    "    }\n",
    "\n",
    "    # ---- Display Performance Table ----\n",
    "    st.write(\"## üìä Model Performance Summary\")\n",
    "    st.dataframe(pd.DataFrame(results).T.sort_values(by=\"F1-score\", ascending=False))\n",
    "\n",
    "    # ---- Confusion Matrix Visualization ----\n",
    "    st.write(\"## üîç Confusion Matrices\")\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "      y_pred = model.predict(X_test)\n",
    "      cm = confusion_matrix(y_test, y_pred)\n",
    "      sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "      axes[idx].set_title(f\"{name}\")\n",
    "      axes[idx].set_xlabel(\"Predicted\")\n",
    "      axes[idx].set_ylabel(\"Actual\")\n",
    "\n",
    "    # Remove extra axes\n",
    "    for j in range(len(models), len(axes)):\n",
    "      fig.delaxes(axes[j])\n",
    "\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # --- Show selected model ---\n",
    "    st.markdown(\"## ‚úÖ Selected Model for Recommendation\")\n",
    "    st.write(\"\"\"We are using **Logistic Regression** as the primary model for predicting company fit and driving the similarity search logic below, based on its strong F1-score and overall performance.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "    # --- Streamlit UI ---\n",
    "    st.subheader(\"üîç Explore 'High' Fit Companies (Gensim TF-IDF Similarity)\")\n",
    "\n",
    "    input_text = st.text_area(\"Enter your company description or summary:\")\n",
    "    if st.button(\"Find similar 'High' fit companies\"):\n",
    "        if not input_text.strip():\n",
    "            st.warning(\"Please enter some text.\")\n",
    "        else:\n",
    "            input_tokens = gensim.utils.simple_preprocess(input_text)\n",
    "            input_tokens_clean = remove_stopwords(clean_tokens(input_tokens))\n",
    "            input_bow = dictionary.doc2bow(input_tokens_clean)\n",
    "\n",
    "            sims = index[tfidf_model[input_bow]]\n",
    "            ranked = sorted(enumerate(sims), key=lambda x: -x[1])\n",
    "\n",
    "            st.write(\"### Top Similar Companies (label = High)\")\n",
    "            count = 0\n",
    "            for idx, score in ranked:\n",
    "                if df.iloc[idx]['label'] == 'High':\n",
    "                    st.markdown(f\"#### üè∑Ô∏è {df.iloc[idx]['Company Name']}\")\n",
    "                    st.markdown(f\"- **Similarity Score:** `{score:.2f}`\")\n",
    "                    st.markdown(f\"> {df.iloc[idx]['Company overview']}\")\n",
    "                    st.markdown(\"---\")\n",
    "                    count += 1\n",
    "                if count >= 5:\n",
    "                    break\n",
    "\n",
    "with tab2:\n",
    "    st.header(\"Topic 2: Candidate Fit Classification\")\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import streamlit as st\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import re\n",
    "    import openpyxl\n",
    "    from underthesea import word_tokenize\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from collections import Counter\n",
    "\n",
    "\n",
    "    # --- Load data from Google Drive local paths ---\n",
    "    @st.cache_data\n",
    "    def load_review_data():\n",
    "        reviews = pd.read_excel(\"Reviews.xlsx\")\n",
    "        overview_reviews = pd.read_excel(\"Overview_Reviews.xlsx\")\n",
    "        overview_companies = pd.read_excel(\"Overview_Companies.xlsx\")\n",
    "\n",
    "        overview_reviews = overview_reviews.rename(columns={\"id\": \"company_id\"})\n",
    "        overview_companies = overview_companies.rename(columns={\"id\": \"company_id\"})\n",
    "\n",
    "        data = reviews.merge(overview_reviews[[\"company_id\", \"Overall rating\"]], left_on=\"id\", right_on=\"company_id\", how=\"left\")\n",
    "        data = data.merge(overview_companies[[\"company_id\", \"Company Name\", \"Company Type\", \"Company size\"]], on=\"company_id\", how=\"left\")\n",
    "\n",
    "        st.write(\"üìé Available columns:\", data.columns.tolist())\n",
    "        return data\n",
    "\n",
    "    # Load data\n",
    "    df_reviews = load_review_data()\n",
    "\n",
    "    # Validate required columns\n",
    "    if 'What I liked' not in df_reviews.columns or 'Suggestions for improvement' not in df_reviews.columns:\n",
    "        st.error(\"‚ùå Required columns 'What I liked' or 'Suggestions for improvement' are missing in the dataset.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Load stopwords and wrong words\n",
    "    with open(\"vietnamese-stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "\n",
    "    with open(\"wrong-word.txt\", encoding=\"utf-8\") as f:\n",
    "        wrong_words = set(f.read().splitlines())\n",
    "\n",
    "    # Clean text function\n",
    "    def clean_text(text):\n",
    "        if pd.isnull(text):\n",
    "            return \"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^a-zA-Z0-9√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠ƒë√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµ\\s]', ' ', text)\n",
    "        text = re.sub(r'\\d+', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = word_tokenize(text, format=\"text\")\n",
    "        words = [w for w in text.split() if w not in stopwords and w not in wrong_words and len(w) > 2]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    # Suggestion classification function\n",
    "    def suggest_improvement(text):\n",
    "        if pd.isnull(text):\n",
    "            return \"Kh√¥ng c√≥ g√≥p √Ω ti√™u c·ª±c\"\n",
    "        text = str(text).lower()\n",
    "        negative_keywords = [\n",
    "            \"kh√¥ng\", \"thi·∫øu\", \"ch∆∞a\", \"overtime\", \"l∆∞∆°ng_th·∫•p\",\n",
    "            \"√°p_l·ª±c\", \"ch·∫≠m\", \"t·ªá\", \"b·∫•t_c√¥ng\", \"qu√°_t·∫£i\", \"stress\"\n",
    "        ]\n",
    "        for kw in negative_keywords:\n",
    "            if kw in text:\n",
    "                return \"C·∫ßn c·∫£i thi·ªán: \" + kw.replace(\"_\", \" \")\n",
    "        return \"Kh√¥ng c√≥ g√≥p √Ω ti√™u c·ª±c\"\n",
    "\n",
    "    # Apply cleaning\n",
    "    df_reviews['What I liked_clean'] = df_reviews['What I liked'].apply(clean_text)\n",
    "    df_reviews['Suggestions_clean'] = df_reviews['Suggestions for improvement'].apply(suggest_improvement)\n",
    "    df_reviews['text_combined'] = df_reviews['What I liked_clean'] + ' ' + df_reviews['Suggestions_clean']\n",
    "\n",
    "    # Feature engineering\n",
    "    features = df_reviews[['text_combined', 'Rating', 'Company Type', 'Company size', 'Overall rating']]\n",
    "    target = df_reviews['Recommend?']\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['Company Type', 'Company size']\n",
    "    features_processed = pd.get_dummies(features, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "    # Chuy·ªÉn ƒë·ªïi text th√†nh TF-IDF features\n",
    "    tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "    text_features = tfidf.fit_transform(features['text_combined'])\n",
    "    # K·∫øt h·ª£p text features v√† c√°c features s·ªë kh√°c\n",
    "    # Drop 'text_combined' and convert to float (after ensuring all are numeric)\n",
    "    numeric_features = features_processed.drop('text_combined', axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.astype('float64')\n",
    "    X = hstack((text_features, numeric_features))\n",
    "    y = target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    #----------------\n",
    "    # Only keeping Logistic Regression, SVM, and XGBoost\n",
    "    # Removing Random Forest, Spark models, and related evaluation logic\n",
    "    # The model training and evaluation will focus on these three models\n",
    "\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, roc_curve,\n",
    "        accuracy_score, precision_score, recall_score, f1_score\n",
    "    )\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # --- Model Training ---\n",
    "\n",
    "    lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr_model.fit(X_train_balanced, y_train_balanced)\n",
    "    lr_pred = lr_model.predict(X_test)\n",
    "    lr_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "    lr_auc = roc_auc_score(y_test == \"Yes\", lr_proba)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test == \"Yes\", lr_proba)\n",
    "\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_balanced, y_train_balanced)\n",
    "    svm_pred = svm_model.predict(X_test)\n",
    "    svm_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "    svm_auc = roc_auc_score(y_test == \"Yes\", svm_proba)\n",
    "    svm_fpr, svm_tpr, _ = roc_curve(y_test == \"Yes\", svm_proba)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_enc = label_encoder.fit_transform(y_train_balanced)\n",
    "    y_test_enc = label_encoder.transform(y_test)\n",
    "    xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train_balanced, y_train_enc)\n",
    "    xgb_pred_enc = xgb_model.predict(X_test)\n",
    "    xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_pred = label_encoder.inverse_transform(xgb_pred_enc)\n",
    "    xgb_auc = roc_auc_score(y_test == \"Yes\", xgb_proba)\n",
    "    xgb_fpr, xgb_tpr, _ = roc_curve(y_test == \"Yes\", xgb_proba)\n",
    "\n",
    "    # --- Visualization ---\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(lr_fpr, lr_tpr, label=f\"Logistic Regression (AUC = {lr_auc:.4f})\")\n",
    "    plt.plot(svm_fpr, svm_tpr, label=f\"SVM (AUC = {svm_auc:.4f})\")\n",
    "    plt.plot(xgb_fpr, xgb_tpr, label=f\"XGBoost (AUC = {xgb_auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve - Selected Models\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Metrics Comparison ---\n",
    "\n",
    "    models_comparison = pd.DataFrame({\n",
    "        \"Model\": [\"Logistic Regression\", \"SVM\", \"XGBoost\"],\n",
    "        \"AUC\": [lr_auc, svm_auc, xgb_auc],\n",
    "        \"Accuracy\": [\n",
    "            accuracy_score(y_test, lr_pred),\n",
    "            accuracy_score(y_test, svm_pred),\n",
    "            accuracy_score(y_test, xgb_pred)\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            precision_score(y_test, lr_pred, pos_label=\"Yes\"),\n",
    "            precision_score(y_test, svm_pred, pos_label=\"Yes\"),\n",
    "            precision_score(y_test, xgb_pred, pos_label=\"Yes\")\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            recall_score(y_test, lr_pred, pos_label=\"Yes\"),\n",
    "            recall_score(y_test, svm_pred, pos_label=\"Yes\"),\n",
    "            recall_score(y_test, xgb_pred, pos_label=\"Yes\")\n",
    "        ],\n",
    "        \"F1-Score\": [\n",
    "            f1_score(y_test, lr_pred, pos_label=\"Yes\"),\n",
    "            f1_score(y_test, svm_pred, pos_label=\"Yes\"),\n",
    "            f1_score(y_test, xgb_pred, pos_label=\"Yes\")\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(models_comparison.sort_values(\"AUC\", ascending=False))\n",
    "\n",
    "    # --- ROC Curve Display inside Streamlit ---\n",
    "    st.subheader(\"üìâ ROC Curve - Logistic Regression vs SVM vs XGBoost\")\n",
    "\n",
    "    fig_roc, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(lr_fpr, lr_tpr, label=f\"Logistic Regression (AUC = {lr_auc:.4f})\")\n",
    "    ax.plot(svm_fpr, svm_tpr, label=f\"SVM (AUC = {svm_auc:.4f})\")\n",
    "    ax.plot(xgb_fpr, xgb_tpr, label=f\"XGBoost (AUC = {xgb_auc:.4f})\")\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC Curve - Selected Models\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    st.pyplot(fig_roc)\n",
    "\n",
    "    # --- Metrics Comparison Table ---\n",
    "    st.subheader(\"üìä Model Performance Summary\")\n",
    "    st.dataframe(models_comparison.sort_values(\"AUC\", ascending=False).round(4))\n",
    "\n",
    "    import streamlit as st\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import joblib\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    # --- App Settings ---\n",
    "    st.set_page_config(page_title=\"ITViec Review Recommendation Predictor\")\n",
    "    st.title(\"üîç Predict 'Recommend' from Employee Review\")\n",
    "    st.markdown(\"D·ª±a tr√™n th√¥ng tin ƒë√°nh gi√° t·ª´ nh√¢n vi√™n ƒë√£ review tr√™n ITViec, d·ª± ƒëo√°n xem h·ªç c√≥ recommend c√¥ng ty hay kh√¥ng.\")\n",
    "\n",
    "    # --- Load Pre-trained Models and Encoders ---\n",
    "    xgb_model = joblib.load(\"xgb_model.pkl\")\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "    onehot_encoder = joblib.load(\"onehot_encoder.pkl\")\n",
    "\n",
    "    # --- Load Company Data ---\n",
    "    overview_companies = pd.read_excel(\n",
    "        \"Overview_Companies.xlsx\"\n",
    "    )\n",
    "    overview_companies = overview_companies.rename(columns={\"Company Name\": \"company_name\"})\n",
    "\n",
    "    # --- Prediction UI ---\n",
    "    st.subheader(\"üìù D·ª± ƒëo√°n theo t√™n c√¥ng ty\")\n",
    "\n",
    "    company_name_list = overview_companies[\"company_name\"].dropna().unique().tolist()\n",
    "    company_name = st.selectbox(\"Ch·ªçn t√™n c√¥ng ty\", sorted(company_name_list))\n",
    "\n",
    "    if st.button(\"D·ª± ƒëo√°n\"):\n",
    "        try:\n",
    "            # L·∫•y th√¥ng tin c√¥ng ty t·ª´ t√™n ƒë√£ ch·ªçn\n",
    "            selected_info = overview_companies[overview_companies[\"company_name\"] == company_name].iloc[0]\n",
    "            company_type = selected_info[\"Company Type\"]\n",
    "            company_size = selected_info[\"Company size\"]\n",
    "\n",
    "            # Encode categorical features\n",
    "            cat_features = pd.DataFrame([[company_type, company_size]], columns=[\"Company Type\", \"Company size\"])\n",
    "            cat_encoded = onehot_encoder.transform(cat_features)  # Do not use .toarray() if sparse_output=False\n",
    "\n",
    "            # T·∫°o m·∫£ng 1010 chi·ªÅu, ch√®n cat_encoded v√†o cu·ªëi\n",
    "            num_total_features = 1010  # s·ªë chi·ªÅu model y√™u c·∫ßu\n",
    "            num_cat_features = cat_encoded.shape[1]\n",
    "\n",
    "            # Kh·ªüi t·∫°o m·∫£ng to√†n 0\n",
    "            final_features = np.zeros((1, num_total_features))\n",
    "\n",
    "            # G√°n cat_encoded v√†o ph·∫ßn cu·ªëi\n",
    "            final_features[0, -num_cat_features:] = cat_encoded\n",
    "\n",
    "            # D·ª± ƒëo√°n\n",
    "            proba = xgb_model.predict_proba(final_features)[0][1]\n",
    "            prediction = label_encoder.inverse_transform([int(proba >= 0.5)])[0]\n",
    "\n",
    "\n",
    "\n",
    "            # Output\n",
    "            st.subheader(\"üîç K·∫øt qu·∫£\")\n",
    "            st.write(f\"**X√°c su·∫•t Recommend:** {proba:.2%}\")\n",
    "            st.success(f\"‚ú® D·ª± ƒëo√°n: **{prediction}**\")\n",
    "\n",
    "        except IndexError:\n",
    "            st.error(\"‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin c√¥ng ty. Vui l√≤ng th·ª≠ l·∫°i.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå L·ªói: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import streamlit as st"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3/OUbYzcFDP78lGnfan66",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
