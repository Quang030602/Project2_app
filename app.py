import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import (
    precision_score, recall_score, f1_score, accuracy_score, confusion_matrix,
    roc_auc_score, roc_curve
)

# Äáº·t tÃªn file cá»‘ Ä‘á»‹nh (cÃ¹ng cáº¥p app.py)
LABEL_ENCODER_PATH = "label_encoder.pkl"
ONEHOT_ENCODER_PATH = "onehot_encoder.pkl"
TFIDF_VECTORIZER_PATH = "tfidf_vectorizer.pkl"
XGB_MODEL_PATH = "xgb_model.pkl"
COMPANY_FILE = "Overview_Companies.xlsx"
REVIEW_FILE = "Reviews.xlsx"
OVERVIEW_REVIEW_FILE = "Overview_Reviews.xlsx"

# PAGE CONFIG (nÃªn Ä‘á»ƒ Ä‘áº§u file)
st.set_page_config(page_title="Company Recommendation & Candidate Classification", layout="wide")

# ================== LOAD MODEL & ENCODER ==================
@st.cache_resource
def load_all_models():
    label_encoder = joblib.load(LABEL_ENCODER_PATH)
    onehot_encoder = joblib.load(ONEHOT_ENCODER_PATH)
    tfidf_vectorizer = joblib.load(TFIDF_VECTORIZER_PATH)
    xgb_model = joblib.load(XGB_MODEL_PATH)
    return label_encoder, onehot_encoder, tfidf_vectorizer, xgb_model

label_encoder, onehot_encoder, tfidf_vectorizer, xgb_model = load_all_models()

# ================== LOAD DATA ==================
@st.cache_data
def load_data():
    df_companies = pd.read_excel(COMPANY_FILE)
    df_reviews = pd.read_excel(REVIEW_FILE)
    df_overview_reviews = pd.read_excel(OVERVIEW_REVIEW_FILE)
    return df_companies, df_reviews, df_overview_reviews

df_companies, df_reviews, df_overview_reviews = load_data()

# ================== SIDEBAR MENU ==================
st.sidebar.title("Project 02")
st.sidebar.caption("Team: Nguyen Quynh Oanh Thao - Nguyen Le Minh Quang")
menu = ["Trang chá»§", "Dá»± Ä‘oÃ¡n cÃ´ng ty", "PhÃ¢n tÃ­ch mÃ´ hÃ¬nh"]
choice = st.sidebar.radio("Menu", menu)

# ================== HOME ==================
if choice == "Trang chá»§":
    st.title("Project 02 - Company Recommendation & Candidate Classification")
    st.markdown("""
    á»¨ng dá»¥ng há»— trá»£:
    - Äá» xuáº¥t cÃ´ng ty phÃ¹ há»£p dá»±a vÃ o ná»™i dung vÃ  dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡.
    - PhÃ¢n tÃ­ch kháº£ nÄƒng "Recommend" cá»§a nhÃ¢n viÃªn/á»©ng viÃªn cho cÃ´ng ty.
    """)
    st.info("Chá»n cÃ¡c tab bÃªn trÃ¡i Ä‘á»ƒ tráº£i nghiá»‡m cÃ¡c chá»©c nÄƒng dá»± Ä‘oÃ¡n!")

# ================== Dá»° ÄOÃN CÃ”NG TY ==================
elif choice == "Dá»± Ä‘oÃ¡n cÃ´ng ty":
    st.header("ğŸ“ Dá»± Ä‘oÃ¡n Recommend cho tÃªn cÃ´ng ty")
    company_name_list = df_companies["Company Name"].dropna().unique().tolist()
    selected_company = st.selectbox("Chá»n tÃªn cÃ´ng ty", sorted(company_name_list))
    if st.button("Dá»± Ä‘oÃ¡n Recommend?"):
        try:
            selected_info = df_companies[df_companies["Company Name"] == selected_company].iloc[0]
            company_type = selected_info["Company Type"]
            company_size = selected_info["Company size"]

            # One-hot encode categorical
            cat_features = pd.DataFrame([[company_type, company_size]], columns=["Company Type", "Company size"])
            cat_encoded = onehot_encoder.transform(cat_features)

            # Chuáº©n bá»‹ input cho model (vector 1010 chiá»u, cat features náº±m cuá»‘i)
            num_total_features = 1010
            num_cat_features = cat_encoded.shape[1]
            final_features = np.zeros((1, num_total_features))
            final_features[0, -num_cat_features:] = cat_encoded

            # Predict
            proba = xgb_model.predict_proba(final_features)[0][1]
            prediction = label_encoder.inverse_transform([int(proba >= 0.5)])[0]
            st.subheader("ğŸ” Káº¿t quáº£")
            st.write(f"**XÃ¡c suáº¥t Recommend:** {proba:.2%}")
            if prediction == "Yes":
                st.success(f"âœ¨ NhÃ¢n viÃªn/á»©ng viÃªn cÃ³ xu hÆ°á»›ng **RECOMMEND** cÃ´ng ty nÃ y.")
            else:
                st.warning(f"âš ï¸ NhÃ¢n viÃªn/á»©ng viÃªn cÃ³ xu hÆ°á»›ng **KHÃ”NG RECOMMEND** cÃ´ng ty nÃ y.")
        except Exception as e:
            st.error(f"Lá»—i: {e}")

# ================== PHÃ‚N TÃCH MÃ” HÃŒNH ==================
elif choice == "PhÃ¢n tÃ­ch mÃ´ hÃ¬nh":
    st.header("ğŸ“Š PhÃ¢n tÃ­ch hiá»‡u suáº¥t mÃ´ hÃ¬nh XGBoost")
    # Káº¿t há»£p review vá»›i cÃ¡c thÃ´ng tin cáº§n thiáº¿t
    df = df_reviews.merge(
        df_overview_reviews[["id", "Overall rating"]].rename(columns={"id": "company_id"}),
        left_on="id", right_on="company_id", how="left"
    ).merge(
        df_companies[["company_id", "Company Name", "Company Type", "Company size"]],
        on="company_id", how="left"
    )
    # Chuáº©n bá»‹ dá»¯ liá»‡u cho model
    categorical_cols = ['Company Type', 'Company size']
    features = df[['What I liked', 'Rating', 'Company Type', 'Company size', 'Overall rating']].copy()
    features = features.fillna("")
    # Káº¿t há»£p text
    features['combined_text'] = features['What I liked'].astype(str)
    text_features = tfidf_vectorizer.transform(features['combined_text'])
    # One-hot encode
    cat_features = features[categorical_cols].fillna("KhÃ¡c")
    cat_encoded = onehot_encoder.transform(cat_features)
    numeric_features = features[['Rating', 'Overall rating']].fillna(0).to_numpy()
    # Káº¿t há»£p all features
    from scipy.sparse import hstack
    X = hstack([text_features, numeric_features, cat_encoded])
    y = df['Recommend?'].fillna("No").to_numpy()

    # Chia test-train
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Predict vÃ  Ä‘Ã¡nh giÃ¡
    y_pred = xgb_model.predict(X_test)
    y_proba = xgb_model.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, pos_label="Yes")
    rec = recall_score(y_test, y_pred, pos_label="Yes")
    f1 = f1_score(y_test, y_pred, pos_label="Yes")
    auc = roc_auc_score((y_test == "Yes").astype(int), y_proba)

    st.write("### ğŸ“ˆ Hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm thá»­:")
    st.write(f"- **Accuracy:** {acc:.4f}")
    st.write(f"- **Precision:** {prec:.4f}")
    st.write(f"- **Recall:** {rec:.4f}")
    st.write(f"- **F1-score:** {f1:.4f}")
    st.write(f"- **AUC:** {auc:.4f}")

    # Hiá»ƒn thá»‹ confusion matrix
    cm = confusion_matrix(y_test, y_pred, labels=["Yes", "No"])
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Yes", "No"], yticklabels=["Yes", "No"], ax=ax)
    ax.set_xlabel("Dá»± Ä‘oÃ¡n")
    ax.set_ylabel("Thá»±c táº¿")
    st.pyplot(fig)

    # ROC curve
    fpr, tpr, _ = roc_curve((y_test == "Yes").astype(int), y_proba)
    fig2, ax2 = plt.subplots()
    ax2.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    ax2.plot([0, 1], [0, 1], 'k--')
    ax2.set_xlabel("False Positive Rate")
    ax2.set_ylabel("True Positive Rate")
    ax2.set_title("ROC Curve")
    ax2.legend()
    st.pyplot(fig2)

    st.markdown("> Dá»¯ liá»‡u vÃ  model sá»­ dá»¥ng hoÃ n toÃ n offline, khÃ´ng gá»­i dá»¯ liá»‡u Ä‘i Ä‘Ã¢u.")

# ========== Háº¾T ==========
